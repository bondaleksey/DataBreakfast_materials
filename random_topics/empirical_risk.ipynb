{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main sources:\n",
    "- Course [Foundations of machine learning][1], \n",
    "- video [3. Introduction to Statistical Learning Theory][2]\n",
    "- book, chapter 4 [Foundations of Machine Learning, Second Edition][3]\n",
    "\n",
    "[1]: https://bloomberg.github.io/foml/#lectures\n",
    "[2]: https://www.youtube.com/watch?v=rqJ8SrnmWu0\n",
    "[3]: https://cs.nyu.edu/~mohri/mlbook/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assume there is a **data generating distribution** $P_{\\mathcal{X} \\times \\mathcal{y}}$\n",
    "- All input/output pairs $(x,y)$ are generated i.i.d. from $P_{\\mathcal{X} \\times \\mathcal{y}}$.\n",
    "- i.i.d. means “independent, and identically distributed’”; practically it means: \n",
    "    1. no covariate shift\n",
    "    2. no concept drift\n",
    "- Want decision function $f(x)$ that generally `“does well on average”`:\n",
    "$l(f(x),y)$ is usually small, in some sense\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Def \n",
    "The **risk** of a decision function $f: \\mathcal{X} \\rightarrow \\mathcal{A}$ is\n",
    "$$R(f) = \\mathbb{E} l(f(x), y) $$\n",
    "\n",
    "In words, it’s the expected loss of f on a new example $(x,y)$ drawn randomly from $P_{\\mathcal{X} \\times \\mathcal{y}}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Risk function cannot be computed`\n",
    "Since we don’t know $P_{\\mathcal{X} \\times \\mathcal{y}}$, we cannot compute the expectation.\n",
    "But we can estimate it...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "books:\n",
    "\n",
    "- M. Кернс, У. Вазирани. Введение в теорию вычислительного обучения. MIT Press, 1994. Учебник.\n",
    "- М. Мохри, А. Ростамизаде и А. Талвалкар. Основы машинного обучения. MIT Press, 2018. Глава 2 содержит подробное рассмотрение PAC-обучаемости. Доступно для чтения через открытый доступ от издателя.\n",
    "- D. Хаусслер. Обзор системы обучения «Вероятно приблизительно правильное» (PAC) . Введение в тему.\n",
    "- Л. Доблестный. Вероятно, приблизительно правильно. Basic Books, 2013. В которой Валиант утверждает, что обучение PAC описывает, как организмы развиваются и учатся.Википедия  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
